{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Lab\n",
    "Nov 12, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[double click to edit\\]\n",
    "\n",
    "Your names:\n",
    "\n",
    "Optional 2-min response (complete at end of lab): one thing you learned/reinforced, one (or more) questions you have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "Use pen(cil) and paper for this part, and enter your responses in this notebook\n",
    "\n",
    "We will build a naive Bayes sentiment classifier for movie reviews using words as features and we will employ add-1 smoothing. Sentiment labels are positive (+) and negative (-). Our corpus has five training instances and one test instance:\n",
    "\n",
    "Training Set:\n",
    "\n",
    "    - just plain boring \n",
    "    - entirely predictable and lacks energy\n",
    "    - no surprises and very few laughs \n",
    "    + very powerful \n",
    "    + the most fun film of the summer \n",
    "\n",
    "Test Set:\n",
    "\n",
    "    ? predictable no fun \n",
    "\n",
    "In a naive Bayes model with words as features, the most probable class *c* for a test instance is:\n",
    "<img src=\"formula.png\" alt=\"formula\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** What class labels are in set C ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive and negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** For the test sentence, what is w ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Compute the prior for the two classes + and -."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P( 'pos' ) = 0.4 = 2/5\n",
    "P( 'neg' ) = 0.6 = 3/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Now compute the likelihoods for each word given the class (leave in the form of fractions). Remember to +1 to the count of each word given each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P( predictable | 'pos' ) = 1/9\n",
    "P( no | 'pos' ) = 1/9\n",
    "P( fun | 'pos' ) = 2/9\n",
    "\n",
    "P( predictable | 'neg' ) = 1/7\n",
    "P( no | 'neg' ) = 1/7\n",
    "P( fun | 'neg' ) = 1/14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Now compute whether the model would predict the sentence in the test set to be of class positive or negative (okay to leave in fractions or to use a calculator).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictable(neg 1/7) no(neg 1/7) fun(pos 2/9) \n",
    "pos = 1/9*2/5 + 1/9*2/5 + 2/9*2/5 = 8/45\n",
    "neg = 1/7*3/5 + 1/7*3/5 + 2/9*3/5 = 3/14 ~ bigger \n",
    "\n",
    "negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6** What would the answer be without add-1 smoothing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the label would be pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NLTK to train a naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of words for each sentence in the training\n",
    "# the first one is provided\n",
    "sent1 = 'just plain boring'.split()\n",
    "sent2 = 'entirely predictable and lacks energy'.split()\n",
    "sent3 = 'no surprises and very few laughs'.split()\n",
    "sent4 = 'very powerful'.split()\n",
    "sent5 = 'the most fun film of the summer'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['just', 'plain', 'boring', 'entirely', 'predictable', 'and', 'lacks', 'energy', 'no', 'surprises', 'and', 'very', 'few', 'laughs', 'very', 'powerful', 'the', 'most', 'fun', 'film', 'of', 'the', 'summer']\n"
     ]
    }
   ],
   "source": [
    "# make a variable called 'words' that appends all five lists of words\n",
    "words = []\n",
    "words.extend(sent1)\n",
    "words.extend(sent2)\n",
    "words.extend(sent3)\n",
    "words.extend(sent4)\n",
    "words.extend(sent5)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a tuple for each review in the training\n",
    "# the first one is provided\n",
    "rev1 = (sent1, 'neg')\n",
    "rev2 = (sent2, 'neg')\n",
    "rev3 = (sent3, 'neg')\n",
    "rev4 = (sent4, 'pos')\n",
    "rev5 = (sent5, 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list called 'revs' that contains the five tuples\n",
    "revs = [rev1, rev2, rev3, rev4, rev5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 20 samples and 23 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# run this, inspect the output, make sure you understand the output\n",
    "all_word_freqs = nltk.FreqDist(w.lower() for w in words)\n",
    "print(all_word_freqs)\n",
    "# for w in words:\n",
    "#     print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(just)': False, 'contains(plain)': False, 'contains(boring)': False, 'contains(entirely)': False, 'contains(predictable)': True, 'contains(and)': False, 'contains(lacks)': False, 'contains(energy)': False, 'contains(no)': True, 'contains(surprises)': False, 'contains(very)': False, 'contains(few)': False, 'contains(laughs)': False, 'contains(powerful)': False, 'contains(the)': False, 'contains(most)': False, 'contains(fun)': True, 'contains(film)': False, 'contains(of)': False, 'contains(summer)': False}\n"
     ]
    }
   ],
   "source": [
    "# this function takes a document (as a string) and returns the\n",
    "# feature values (word counts) for all the words in the training data\n",
    "document = 'predictable no fun'.split()\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in all_word_freqs:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "print(document_features(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect document_features to return when you pass in the test document ('predictable no fun')?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter answer here\n",
    "# it would return false for all the words except fun, as the training data only contains the word fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now call document_features on the test document, print the output\n",
    "\"\"\"\n",
    "{'contains(just)': False, 'contains(plain)': False, 'contains(boring)': False, 'contains(entirely)': False, \n",
    " 'contains(predictable)': True, 'contains(and)': False, 'contains(lacks)': False, 'contains(energy)': False, \n",
    " 'contains(no)': True, 'contains(surprises)': False, 'contains(very)': False, 'contains(few)': False, \n",
    " 'contains(laughs)': False, 'contains(powerful)': False, 'contains(the)': False, 'contains(most)': False, \n",
    " 'contains(fun)': True, 'contains(film)': False, 'contains(of)': False, 'contains(summer)': False}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have completed the steps above, this code cell should output the \n",
    "# same class that you computed in Part 1\n",
    "train_set = [(document_features(d), c) for (d,c) in revs]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier.classify(document_features('predictable no fun'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the last line of the above cell and try out other test sentences\n",
    "# classifier.classify(document_features('i hate this'.split()))\n",
    "# classifier.classify(document_features('beautiful'.split()))\n",
    "classifier.classify(document_features('fun and powerful'.split()))\n",
    "# classifier.classify(document_features('fun in summer'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the behavior match with your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, it matches my expectations for negative sentences but not positive.\n",
    "I believe this might be because we have more training data for the negative sentences and less for positive.\n",
    "When we use words that appeared in the positive training data, it classifies it correctly, but doesn't otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If time remains, try creating new train and test sets, or see https://www.nltk.org/book/ch06.html section 1.3, to explore creating a naive Bayes model using NLTK's movie review data set. It has about 600 labeled reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
